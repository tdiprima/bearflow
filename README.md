# ğŸ» Bearflow: Workflow Orchestration Playground

Welcome to **Bearflow**, where pipelines roam free and tasks get tamed.  
This repo is a mini playground for exploring different **workflow management systems** â€” from the classics to the shiny new ones.  

It's not production. It's **proof-of-concept territory**.  
Bring snacks, curiosity, and maybe Redis.  

## ğŸ—ºï¸ What's Inside

Each folder/file is a tiny POC showing a 2-task workflow:

Task A â†’ Task B â†’ "Flow complete!"

| Framework | Filename | Vibe | Notes |
|------------|-----------|------|-------|
| ğŸŒ€ **Prefect** | `bearflow_prefect.py` | smooth, modern | Pythonic, easy orchestration |
| âš™ï¸ **Celery** | `celery_den.py` | old reliable | Great for async queues, needs broker |
| ğŸ§© **Dagster** | `pipeline_paws.py` | data-pipeline friendly | strong typing + observability |
| ğŸª¶ **Airflow-lite** | `aircub_dag.py` | enterprise throwback | Big overhead, good scheduler |
| â³ **Temporal** | `temporal_cave.py` | next-gen vibes | durable, resilient workflows |

## ğŸ§° Setup

If you're using [`uv`](https://github.com/astral-sh/uv) (and you should), grab the dependencies you need:

### Install them all

```bash
uv add prefect celery dagster apache-airflow temporalio redis
```

## ğŸ§ª Running the POCs

Each script can be run locally:

### Prefect

```bash
python bearflow_prefect.py
```

### Celery

```bash
# Terminal A: start redis
./redisctl.sh up
# Or
redis-server

# Terminal 1: start worker
celery -A celery_den worker --loglevel=info

# Terminal 2: trigger tasks
python -c "from celery_den import task_a, task_b; task_a.delay(); task_b.delay()"
```

### Dagster

```bash
python pipeline_paws.py
```

### Airflow-lite

```bash
# Place `aircub_dag.py` inside your Airflow `dags/` directory
airflow dags trigger aircub_dag
```

### Temporal

```bash
# Terminal 1: Start Temporal server
temporal server start-dev

# Terminal 2: Run the worker
python temporal_cave.py
# You should see: Starting Temporal worker...

# Terminal 3: Trigger the workflow
python temporal_trigger.py
```

## ğŸ§  Quick Comparison

| Framework    | Setup Effort | Learning Curve | Maintenance   | Scalability   | Bear's Hot Take                                    |
| ------------ | ------------ | -------------- | ------------- | ------------- | -------------------------------------------------- |
| **Prefect**  | â­â­           | ğŸ§© Smooth      | ğŸŒ¿ Low        | ğŸš€ High       | *Feels like the future of "just works" workflows*  |
| **Celery**   | â­            | ğŸª“ Moderate    | ğŸ§± Medium     | ğŸš€ High       | *Still the champ for simple queues, but dusty*     |
| **Dagster**  | â­â­           | ğŸ“ˆ Steep       | ğŸŒ± Manageable | ğŸš€ High       | *Data teams love it â€” structured and robust*       |
| **Airflow**  | â­â­â­          | ğŸ§  Chunky      | ğŸ§± Heavy      | ğŸš€ Very high  | *Powerful, but feels like managing a small planet* |
| **Temporal** | â­â­â­          | ğŸ§© Medium      | ğŸŒ¿ Low        | ğŸš€ğŸš€ğŸš€ Insane | *Resilient, future-proof, but needs infra love*    |

## ğŸª„ Future Ideas

* Add async workflows for Celery & Prefect
* Compare logging/monitoring tools (Prefect Cloud vs Dagit vs Temporal UI)
* Dockerize everything for local orchestration lab
* Write a wrapper script (`run_all_bears.py`) to test all flows together

## ğŸ» Closing Thoughts

"Workflows are just glorified to-do lists for machines."  
â€” Bear, probably

This repo exists so you can explore what feels **right-sized** for your team â€” whether it's a tiny Python job runner or a full-blown orchestrator.

No pressure, no vendor lock-in, just vibes.

**License:** MIT  
**Maintainer:** ğŸ§¸ Bear  
**Mood:** âœ¨ mildly chaotic but organized

<br>
